#!/usr/bin/env python3

LANG1 = "en"
LANG2 = "ja"

MOSES = "/root/mosesdecoder"
MGIZA = "/root/mgiza"
MKCLS = "/root/clustercat/bin/mkcls"
# MKCLS = "/root/mgiza/mgizapp/bin/mkcls"

PROFILING = ""

WORDTOK1 = "/root/mosesdecoder/scripts/tokenizer/tokenizer.perl -q -b -a -l en"
WORDTOK2 = "mecab -Owakati"

CORPUS_PREFIXES = [
    "/data/bitextor/corpus/OpenSubtitles",
    "/data/bitextor/corpus/Tatoeba",
    "/data/bitextor/corpus/QED",
    "/data/bitextor/corpus/News-Commentary",
    "/data/bitextor/corpus/EUbookshop",
    "/data/bitextor/corpus/GlobalVoices",
    "/data/bitextor/corpus/JESC",
    "/data/bitextor/corpus/TED",
    "/data/bitextor/corpus/KFTT",
]

PPROC_CORPUS_DIR = "/data/bitextor/work/temppproc"
MGIZA_MODEL_DIR = "/data/bitextor/work/tmpgiza"

DIC = f"/data/bitextor/dic_data/{LANG1}-{LANG2}.dic"

HUNALIGN_DIC = f"hunalign.{LANG1}-{LANG2}.dic"

OUTPUT = [
    HUNALIGN_DIC
]

rule all:
    input:
        expand("{target}", target=OUTPUT)

# ================================= TRAIN HUNALIGN DIC ================================= #

rule tokenize_file_l1:
    input:
        expand("{dataset}.{lang1}-{lang2}.{lang1}.xz", dataset=CORPUS_PREFIXES, lang1=LANG1, lang2=LANG2)
    output:
        f"{{dir}}/corpus.tok.{LANG1}.xz"
    shell:
        "mkdir -p {wildcards.dir}; "
        "xzcat -T 0 -f {input} | sed \"s/&apos;/'/g\" | sed 's/&quot;/\"/g' | sed 's/&amp;/\&/g' | {WORDTOK1} | xz -T 0 > {output}"

rule tokenize_file_l2:
    input:
        expand("{dataset}.{lang1}-{lang2}.{lang2}.xz", dataset=CORPUS_PREFIXES, lang1=LANG1, lang2=LANG2)
    output:
        f"{{dir}}/corpus.tok.{LANG2}.xz"
    shell:
        "mkdir -p {wildcards.dir}; "
        "xzcat -T 0 -f {input} | sed \"s/&apos;/'/g\" | sed 's/&quot;/\"/g' | sed 's/&amp;/\&/g' | {WORDTOK2} | xz -T 0 > {output}"

rule lowercase:
    input:
        f"{{dir}}/corpus.tok.{{lang}}.xz"
    output:
        f"{{dir}}/corpus.tok.low.{{lang}}"
    shell:
        "xzcat {input} | {PROFILING} {MOSES}/scripts/tokenizer/lowercase.perl > {output}"

rule clean:
    input:
        f"{{dir}}/corpus.tok.low.{LANG1}",
        f"{{dir}}/corpus.tok.low.{LANG2}"
    output:
        f"{{dir}}/corpus.clean.{LANG1}",
        f"{{dir}}/corpus.clean.{LANG2}"
    shell:
        "{PROFILING} perl {MOSES}/scripts/training/clean-corpus-n.perl {wildcards.prefix}.tok.low {LANG1} {LANG2} {wildcards.prefix}.clean 1 80 {wildcards.prefix}.lines-retained"

rule plain2snt:
    input:
        l1 = f"{PPROC_CORPUS_DIR}/corpus.clean.{LANG1}",
        l2 = f"{PPROC_CORPUS_DIR}/corpus.clean.{LANG2}"
    output:
        snt_2_1 = f"{MGIZA_MODEL_DIR}/corpus.{LANG2}-{LANG1}-int-train.snt",
        snt_1_2 = f"{MGIZA_MODEL_DIR}/corpus.{LANG1}-{LANG2}-int-train.snt",
        vcb1 = f"{MGIZA_MODEL_DIR}/corpus.{LANG1}.vcb",
        vcb2 = f"{MGIZA_MODEL_DIR}/corpus.{LANG2}.vcb"
    priority:
        40
    shell:
        "mkdir -p {MGIZA_MODEL_DIR}; "
        "{MGIZA}/mgizapp/bin/plain2snt {input.l1} {input.l2} 2> /dev/null > /dev/null; "
        "mv {PPROC_CORPUS_DIR}/corpus.clean.{LANG1}_corpus.clean.{LANG2}.snt {output.snt_2_1}; "
        "mv {PPROC_CORPUS_DIR}/corpus.clean.{LANG2}_corpus.clean.{LANG1}.snt {output.snt_1_2}; "
        "cp {PPROC_CORPUS_DIR}/corpus.clean.{LANG1}.vcb {output.vcb1}; "
        "cp {PPROC_CORPUS_DIR}/corpus.clean.{LANG2}.vcb {output.vcb2}; "

rule mkcls:
    input:
        f"{PPROC_CORPUS_DIR}/corpus.clean.{{lang}}"
    output:
        f"{MGIZA_MODEL_DIR}/corpus.{{lang}}.vcb.classes"
    priority:
        40
    shell:
        "{PROFILING} {MKCLS} -c50 -n2 -p{input} -V{output} opt 2> /dev/null > /dev/null"

rule snt2cooc:
    input:
        vcb1 = "{prefix}.{l1}.vcb",
        vcb2 = "{prefix}.{l2}.vcb",
        vcb1cls = "{prefix}.{l1}.vcb.classes",
        vcb2cls = "{prefix}.{l2}.vcb.classes",
        snt = "{prefix}.{l2}-{l1}-int-train.snt"
    output:
        "{prefix}.{l2}-{l1}.cooc"
    shell:
        "{PROFILING} {MGIZA}/mgizapp/bin/snt2cooc {output} {input.vcb1} {input.vcb2} {input.snt} 2> /dev/null"

rule mgiza:
    input:
        vcb1 = "{prefix}.{l1}.vcb",
        vcb2 = "{prefix}.{l2}.vcb",
        snt = "{prefix}.{l2}-{l1}-int-train.snt",
        cooc = "{prefix}.{l2}-{l1}.cooc"
    output:
        "{prefix}.{l2}-{l1}.t3.final"
    shell:
        "{PROFILING} {MGIZA}/mgizapp/bin/mgiza -ncpus 16 -CoocurrenceFile {input.cooc} -c {input.snt} -m1 5 -m2 0 -m3 3 -m4 3 -mh 5 -m5 0 -model1dumpfrequency 1 -o {wildcards.prefix}.{wildcards.l2}-{wildcards.l1} -s {input.vcb1} -t {input.vcb2} -emprobforempty 0.0 -probsmooth 1e-7 2> /dev/null > /dev/null"

rule filter_dics:
    input:
        "{prefix}.vcb"
    output:
        "{prefix}.filtered.vcb"
    shell:
        "cat {input} | egrep ' [^ ][^ ]+$' > {output}"

rule symmetrise_dic:
    """ Obtaining the harmonic probability of each pair of words in both directions and filtering out those with less than p=0.2; printing the dictionary
    """
    input:
        vcb1 = f"{MGIZA_MODEL_DIR}/corpus.{LANG1}.filtered.vcb",
        vcb2 = f"{MGIZA_MODEL_DIR}/corpus.{LANG2}.filtered.vcb",
        t3_1 = f"{MGIZA_MODEL_DIR}/corpus.{LANG1}-{LANG2}.t3.final",
        t3_2 = f"{MGIZA_MODEL_DIR}/corpus.{LANG2}-{LANG1}.t3.final"
    output:
        DIC
    run:
        svocabulary = {}
        tvocabulary = {}
        svcb = open(input.vcb1, "r")
        tvcb = open(input.vcb2, "r")
        for line in svcb:
            item = line.strip().split(" ")
            svocabulary[item[0]] = item[1]

        for line in tvcb:
            item = line.strip().split(" ")
            tvocabulary[item[0]] = item[1]

        t3dic = {}
        t3s = open(input.t3_1, "r")
        t3t = open(input.t3_2, "r")
        for line in t3t:
            item = line.strip().split(" ")
            if item[1] in t3dic:
                t3dic[item[1]][item[0]] = item[2]
            else:
                t3dic[item[1]] = {}
                t3dic[item[1]][item[0]] = item[2]

        dic = open(output[0], "wt")
        dic.write(LANG1+"\t"+LANG2+"\n")
        for line in t3s:
            item = line.strip().split(" ")
            if item[0] in t3dic:
                if item[1] in t3dic[item[0]]:
                    value1 = float(t3dic[item[0]][item[1]])
                    value2 = float(item[2])
                    hmean = 2/((1/value1)+(1/value2))

                    if hmean > 0.1:
                        if item[1] in svocabulary and item[0] in tvocabulary:
                            word1 = svocabulary[item[1]]
                            word2 = tvocabulary[item[0]]
                            if word1.isalpha() or word2.isalpha():
                                dic.write("{0}\t{1}\n".format(word1, word2))
        svcb.close()
        tvcb.close()
        t3s.close()
        t3t.close()
        dic.close()
        os.sync()

rule hunalign_dic:
    """ Build hunalign dictionary
    """
    input:
        expand("{dic}", dic=DIC)
    output:
        HUNALIGN_DIC
    run:
        with open(output[0], "wt") as outw:
            with open(input[0], "rt") as inr:
                header = inr.readline().strip()
                langs = header.split("\t")
                if langs[0] == LANG1 and langs[1] == LANG2:
                    inverse = True
                else:
                    inverse = False
                for inline in inr:
                    columns = inline.strip().split("\t")
                    if inverse:
                        outw.write(columns[1]+" @ "+columns[0]+"\n")
                    else:
                        outw.write(columns[0]+" @ "+columns[1]+"\n")
