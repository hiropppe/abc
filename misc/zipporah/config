# This file has location variables used throughout the system
# Please refer to the paper https://www.cs.jhu.edu/~hxu/zipporah.pdf for details
# for the method.

input_lang=en
output_lang=ja

#==============================================================================
working=./work
ROOT=/root/zipporah

moses=/root/mosesdecoder

# model variables
#==============================================================================

clean_stem_good=pproc/corpus.en-ja.good
clean_stem_bad=pproc/corpus.en-ja.bad
clean_stem_dev=pproc/corpus.en-ja.dev

# you probably don't need to change the variables below this point.
#==============================================================================

aligner=fast-align
fast_align_build=/root/fast_align/build
align_job=1

# Those 2 variables has to do with generating word dictionaries. The dictionary
# computes, for a word-pair {de, en}, p(de | en) and p(en | de), computed by a
# simple counting method.
dict_count_thresh=1  # Only words with counts larger than this number is considered for numerator.
dict_total_count_thresh=1  # Only words with counts larger than this number is considered for denominator.

gridengine=false

#==============================================================================
# features to use
#==============================================================================

bow_constant=0.0001 # This has to do with KL-divergence computation when we compute
                    # scores. A constant is needed to be added to the denominator
                    # to avoid division by 0. Please refer to the paper (section 3.1.1)
                    # https://www.cs.jhu.edu/~hxu/zipporah.pdf for details.
translation_num_jobs=50

ngram_order=5       # n-gram order for language modeling.
word_count=30000    # we take top n most frequent words in the corpus to train
                    # language models, and word_count is the size of the shortlist.
                    # An out-of-shortlist word will be mapped to the least frequent
                    # word in the shortlist for computing probabilities.

# for each number in the string, we will generate parallel sentence pairs picked from the original corpus such that
# their total number of words doesn't exceed the number.
num_words_to_select="500000 1000000 2000000 5000000 10000000 20000000 50000000 100000000 200000000 250000000 350000000 400000000"

#==============================================================================
# Below here is automatic scripts. Do not change anything
#==============================================================================

set -e

if [ "$modeldir" != "" ]; then
  for i in $modeldir/lm.$input_lang $modeldir/lm.$output_lang $modeldir/dict.${input_lang}-${output_lang} $modeldir/dict.${output_lang}-${input_lang}; do
    [ ! -f $i ] && ( echo "model file $i does not exist" >&2 )
  done
fi
lang_pair=${input_lang}-${output_lang}

function check_equal_lines {
  n1=`wc -l $1 | awk '{print $1}'`
  n2=`wc -l $2 | awk '{print $1}'`
  if [ $n1 -ne $n2 ]; then
    echo "Unequal number of lines: $1 and $2" && exit 1
  fi
}
